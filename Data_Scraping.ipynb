{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"10LCvdYOk5PZOp7GzMcq9SSNFW4xPtvuK","authorship_tag":"ABX9TyMUoFSQI2SVPR7f7cZMZgK2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["FreshersWorld Job Scrapper"],"metadata":{"id":"A-ZLvZvqjK9n"}},{"cell_type":"code","source":["!pip install requests beautifulsoup4 pandas\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qarn3HY_jvIH","executionInfo":{"status":"ok","timestamp":1741706954589,"user_tz":-330,"elapsed":3528,"user":{"displayName":"Vansh Modi","userId":"09085497172723149184"}},"outputId":"d9c98320-7548-47b4-950a-755654fa6b29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.12.2)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"]}]},{"cell_type":"markdown","source":["Scrap Single Page First"],"metadata":{"id":"Oe6LzucOGXCG"}},{"cell_type":"code","source":["# Extract job postings\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# Define the Freshersworld URL for scraping\n","url = \"https://www.freshersworld.com/jobs/jobsearch\"\n","\n","# Send request and get page content\n","headers = {\"User-Agent\": \"Mozilla/5.0\"}\n","response = requests.get(url, headers=headers)\n","\n","if response.status_code == 200:\n","    print(\"Page fetched successfully!\")\n","    soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","    # Extracting job listings\n","    jobs = []\n","\n","    for job in soup.find_all(\"div\", class_=\"job-desc-block\"):\n","        try:\n","            title = job.find(\"span\", class_=\"wrap-title seo_title\").text.strip()\n","        except:\n","            title = \"N/A\"\n","\n","        try:\n","            company = job.find(\"h3\", class_=\"latest-jobs-title font-16 margin-none inline-block company-name\").text.strip()\n","        except:\n","            company = \"N/A\"\n","\n","        try:\n","            location = job.find(\"span\", class_=\"job-location display-block modal-open job-details-span\").text.strip()\n","        except:\n","            location = \"N/A\"\n","\n","        try:\n","            experience = job.find(\"span\", class_=\"experience job-details-span\").text.strip()\n","        except:\n","            experience = \"N/A\"\n","\n","        try:\n","            salary = job.find(\"span\", class_=\"qualifications display-block modal-open pull-left job-details-span\").text.strip()\n","        except:\n","            salary = \"N/A\"\n","\n","        jobs.append([title, company, location, experience, salary])\n","\n","    # Convert to DataFrame\n","    df = pd.DataFrame(jobs, columns=[\"Job Title\", \"Company\", \"Location\", \"Experience\", \"Salary\"])\n","\n","    # Save to Excel\n","    df.to_excel(\"Freshersworld_Jobs.xlsx\", index=False)\n","\n","    print(\"Data saved successfully!\")\n","else:\n","    print(\"Failed to fetch the page.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6tG0aKyemOqz","executionInfo":{"status":"ok","timestamp":1741711253529,"user_tz":-330,"elapsed":3201,"user":{"displayName":"Vansh Modi","userId":"09085497172723149184"}},"outputId":"212d4d76-40f0-4376-d43a-4f575c945908"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Page fetched successfully!\n","Data saved successfully!\n"]}]},{"cell_type":"markdown","source":["Srap Multiple Pages"],"metadata":{"id":"0_9FTm12mX3n"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import time\n","\n","# Function to scrape job listings from multiple pages\n","def scrape_freshersworld_jobs(pages=5):\n","    base_url = \"https://www.freshersworld.com/jobs/jobsearch\"\n","    job_list = []\n","\n","    for page in range(1, pages + 1):\n","        print(f\"Scraping page {page}...\")\n","        url = f\"{base_url}?&limit=20&offset={(page-1) * 20}\"\n","        response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n","\n","        if response.status_code != 200:\n","            print(\"Failed to fetch page\", page)\n","            continue\n","\n","        soup = BeautifulSoup(response.text, 'html.parser')\n","        job_blocks = soup.find_all('div', class_='col-md-12 col-xs-12 job_listing_alignment')\n","\n","        for job in job_blocks:\n","            try:\n","                title = job.find('span', class_='wrap-title seo_title').text.strip()\n","                company = job.find('h3', class_='latest-jobs-title').text.strip()\n","                location = job.find('span', class_='job-location').text.strip()\n","                experience = job.find('span', class_='experience job-details-span').text.strip()\n","                salary = job.find('span', class_='qualifications display-block').text.strip()\n","\n","                job_list.append([title, company, location, experience, salary])\n","            except AttributeError:\n","                continue\n","\n","        time.sleep(2)  # Adding delay to avoid getting blocked\n","\n","    return job_list\n","\n","# Scraping jobs from multiple pages\n","jobs_data = scrape_freshersworld_jobs(pages=5)\n","\n","# Creating DataFrame\n","df = pd.DataFrame(jobs_data, columns=['Job Title', 'Company', 'Location', 'Experience', 'Salary'])\n","\n","# Saving to Excel\n","excel_file = \"/content/Freshersworld_Jobs.xlsx\"\n","df.to_excel(excel_file, index=False)\n","print(f\"Scraped {len(df)} job postings and saved to Excel: {excel_file}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zQ5rfHIXmXVw","executionInfo":{"status":"ok","timestamp":1741712246337,"user_tz":-330,"elapsed":16276,"user":{"displayName":"Vansh Modi","userId":"09085497172723149184"}},"outputId":"14a59c43-debd-4d92-888a-b50b2508a900"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Scraping page 1...\n","Scraping page 2...\n","Scraping page 3...\n","Scraping page 4...\n","Scraping page 5...\n","Scraped 0 job postings and saved to Excel: /content/Freshersworld_Jobs.xlsx\n"]}]},{"cell_type":"markdown","source":["Updating excel sheet as new job posting"],"metadata":{"id":"3YYbz-OtLRXF"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import time\n","import os\n","\n","# Path to the existing Excel file\n","excel_file = \"/content/Freshersworld_Jobs.xlsx\"\n","\n","# Function to read existing job data\n","def read_existing_jobs(file_path):\n","    if os.path.exists(file_path):\n","        return pd.read_excel(file_path)\n","    return pd.DataFrame(columns=['Job Title', 'Company', 'Location', 'Experience', 'Salary'])\n","\n","# Function to scrape job listings\n","def scrape_freshersworld_jobs(pages=5):\n","    base_url = \"https://www.freshersworld.com/jobs/jobsearch\"\n","    job_list = []\n","\n","    for page in range(1, pages + 1):\n","        print(f\"Scraping page {page}...\")\n","        url = f\"{base_url}?&limit=20&offset={(page-1) * 20}\"\n","        response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n","\n","        if response.status_code != 200:\n","            print(\"Failed to fetch page\", page)\n","            continue\n","\n","        soup = BeautifulSoup(response.text, 'html.parser')\n","        job_blocks = soup.find_all('div', class_='col-md-12 col-xs-12 job_listing_alignment')\n","\n","        for job in job_blocks:\n","            try:\n","                title = job.find('span', class_='wrap-title seo_title').text.strip()\n","                company = job.find('h3', class_='latest-jobs-title').text.strip()\n","                location = job.find('span', class_='job-location').text.strip()\n","                experience = job.find('span', class_='experience job-details-span').text.strip()\n","                salary = job.find('span', class_='qualifications display-block').text.strip()\n","\n","                job_list.append([title, company, location, experience, salary])\n","            except AttributeError:\n","                continue\n","\n","        time.sleep(2)  # Adding delay to avoid getting blocked\n","\n","    return pd.DataFrame(job_list, columns=['Job Title', 'Company', 'Location', 'Experience', 'Salary'])\n","\n","# Load existing jobs\n","existing_jobs = read_existing_jobs(excel_file)\n","\n","# Scrape new job data\n","new_jobs = scrape_freshersworld_jobs(pages=5)\n","\n","# Combine old and new data, remove duplicates\n","updated_jobs = pd.concat([existing_jobs, new_jobs]).drop_duplicates().reset_index(drop=True)\n","\n","# Save updated job listings to the same Excel file\n","updated_jobs.to_excel(excel_file, index=False)\n","\n","print(f\"Updated job postings saved to: {excel_file}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJTab-uLmijJ","executionInfo":{"status":"ok","timestamp":1741713089019,"user_tz":-330,"elapsed":17797,"user":{"displayName":"Vansh Modi","userId":"09085497172723149184"}},"outputId":"01c7dfb0-e499-455e-81f0-553c39453678"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Scraping page 1...\n","Scraping page 2...\n","Scraping page 3...\n","Scraping page 4...\n","Scraping page 5...\n","Updated job postings saved to: /content/Freshersworld_Jobs.xlsx\n"]}]},{"cell_type":"markdown","source":["Prototype the model with a single record"],"metadata":{"id":"N4Q6KOkBpbFh"}},{"cell_type":"code","source":["from google.colab import drive\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import os\n","import time\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Set path for saving the Excel file\n","excel_path = \"/content/drive/MyDrive/JobScraper/Freshersworld_Jobs.xlsx\"\n","\n","# Function to scrape job listings from multiple pages\n","def scrape_freshersworld_jobs(pages=5):\n","    base_url = \"https://www.freshersworld.com/jobs/jobsearch\"\n","    job_list = []\n","\n","    for page in range(1, pages + 1):\n","        print(f\"Scraping page {page}...\")\n","        url = f\"{base_url}?&limit=20&offset={(page-1) * 20}\"\n","        response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n","\n","        if response.status_code != 200:\n","            print(\"Failed to fetch page\", page)\n","            continue\n","\n","        soup = BeautifulSoup(response.text, 'html.parser')\n","        job_blocks = soup.find_all('div', class_='col-md-12 col-xs-12 job_listing_alignment')\n","\n","        for job in job_blocks:\n","            try:\n","                title = job.find('span', class_='wrap-title seo_title').text.strip()\n","                company = job.find('h3', class_='latest-jobs-title').text.strip()\n","                location = job.find('span', class_='job-location').text.strip()\n","                experience = job.find('span', class_='experience job-details-span').text.strip()\n","                salary = job.find('span', class_='qualifications display-block').text.strip()\n","\n","                job_list.append([title, company, location, experience, salary])\n","            except AttributeError:\n","                continue\n","\n","        time.sleep(2)  # Adding delay to avoid getting blocked\n","\n","    return job_list\n","\n","# Load existing data if file exists\n","if os.path.exists(excel_path):\n","    existing_df = pd.read_excel(excel_path)\n","else:\n","    existing_df = pd.DataFrame(columns=['Job Title', 'Company', 'Location', 'Experience', 'Salary'])\n","\n","# Scrape jobs\n","new_jobs_data = scrape_freshersworld_jobs(pages=5)\n","new_df = pd.DataFrame(new_jobs_data, columns=['Job Title', 'Company', 'Location', 'Experience', 'Salary'])\n","\n","# Append new jobs and remove duplicates\n","final_df = pd.concat([existing_df, new_df]).drop_duplicates().reset_index(drop=True)\n","\n","# Save updated data back to Excel\n","final_df.to_excel(excel_path, index=False)\n","print(f\"Updated Excel file saved at: {excel_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-7LPEfZmOVdC","executionInfo":{"status":"ok","timestamp":1741716496031,"user_tz":-330,"elapsed":74165,"user":{"displayName":"Vansh Modi","userId":"09085497172723149184"}},"outputId":"91a1e4a1-df64-4855-cbe4-29a5ddeb282d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Scraping page 1...\n","Scraping page 2...\n","Scraping page 3...\n","Scraping page 4...\n","Scraping page 5...\n","Updated Excel file saved at: /content/drive/MyDrive/JobScraper/Freshersworld_Jobs.xlsx\n"]}]},{"cell_type":"code","source":["!git config --global user.name \"vanshmodii\"\n","!git config --global user.email \"vanshmodi5@gmail.com\"\n"],"metadata":{"id":"B8re3FFrmZfL","executionInfo":{"status":"ok","timestamp":1741753734290,"user_tz":-330,"elapsed":221,"user":{"displayName":"Vansh Modi","userId":"09085497172723149184"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!git clone https://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@github.com/vanshmodii/Freshersworld-Scraper.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1qSHeVh2mZ5b","executionInfo":{"status":"ok","timestamp":1741754025058,"user_tz":-330,"elapsed":525,"user":{"displayName":"Vansh Modi","userId":"09085497172723149184"}},"outputId":"876da519-0fb3-49e4-8215-bfc464c61aca"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Freshersworld-Scraper'...\n","remote: Enumerating objects: 3, done.\u001b[K\n","remote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (3/3), done.\n"]}]},{"cell_type":"code","source":["import shutil\n","\n","# Move the Excel file\n","shutil.move(\"/mnt/data/Freshersworld_Jobs.xlsx\", \"/content/Freshersworld-Scraper\")\n","\n","# Move the Python script\n","shutil.move(\"/content/Freshersworld_Scraper.py\", \"/content/Freshersworld-Scraper\")\n"],"metadata":{"id":"Mf37sg3ZmaSO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"06fJ01Mzmapo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wpJxnLgJmbQ-"},"execution_count":null,"outputs":[]}]}